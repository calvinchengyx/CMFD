---
title: "CMFD Memo"
output: html_notebook
---
# Chinese Moral Foundation Dictionary Project
## 1. MFD Translation
### 1.1 MFD dictionary collection

We first collected all words in MFD1.0 (Graham et al., 2009) and MFD2.0 (Frimmer et al., 2019). MFD1.0 has two sources: one is the appendix used in Gramham and his colleagues' paper; the other is from their official website [moralfoundation.org](https://moralfoundations.org/wp-content/uploads/files/downloads/moral%20foundations%20dictionary.dic). Two sources are almost the same, except that the web source kepts slightly more meta data and words. More specificly, it (1) differentiated vice/virtue; (2) keep a general morality category; (3) has 64 more words (41 from the general category). A brief comparison is listed as below. Therefore, we used the web source for MFD1.0.

MFD1 word count|paper appendix|web source|
----|---|---|
care|51|51
fairness|44|44|
ingroup|50|52|
authority|70|82|
purity|80|89|
general|0|41|
all|295|359|

Then, I collected MFD2.0 from [OSF](https://osf.io/ezn37/). Compared to MFD1.0, MFD2.0 includes more words and it does not have any word stems. It should be noted that, not all words/word stems in MFD1.0 are in MFD2.0. So I merged two dictionaries and came up with `mfd3`, keeping as much metadata as possible.

To transfrom all word stems to complete words, i refered to [Onelook](https://www.onelook.com/) - an online English dictinoary search engine. It would automatically complete word stems and return relevant common words. For example, word stem "moral*" with "filter by commonness and common words" option in the Onelook would return 19 relevant words including "moral", "morality", "morale" etc. It should be noted the complete words might not be moral relevant sometime, and it needs human verifications afterwards. 

As a result, after mergeing MFD1.0 and 2.0, I collected 2,517 unique moral English words in `mfd3`, waiting to be translated. 


```{r data collection}
library(rvest)
### get mfd1.0
# download.file("https://moralfoundations.org/wp-content/uploads/files/downloads/moral%20foundations%20dictionary.dic", destfile = "mfd1_org.dic")
mfd1 = quanteda:::read_dict_liwc("mfd1_org.dic")
### get mfd2.0
mfd2 = quanteda:::read_dict_liwc("mfd2.0.dic")

### some data cleaning before merging the data
# unify the names in mfd1 and mfd2
names(mfd1) = tolower(names(mfd1))
names(mfd2) = gsub("\\.","",names(mfd2))
names(mfd1) = c("carevirtue","carevice","fairnessvirtue","fairnessvice","loyaltyvirtue","loyaltyvice","authorityvirtue","authorityvice","sanctityvirtue","sanctityvice","moralitygeneral")

# get rid of necessary list layers
for (i in 1:length(mfd1)){
  mfd1[names(mfd1)[i]]= mfd1[names(mfd1)[i]][1]
}

# check whether the word in mfd1 is in mfd2
mfd_lack = list()
for (i in 1:10){
  x = mfd1[[i]][[1]]
  y = mfd2[[i]][[1]]
  z = c()
  for (j in 1:length(x)){
    m = grep(x[j], y) # check if the word has a position in mfd2.0
    if (length(m)==0){
      z = c(z, x[j])
      mfd_lack[[i]] = z
    }
  }
}

names(mfd_lack) = c("carevirtue","carevice","fairnessvirtue","fairnessvice","loyaltyvirtue","loyaltyvice","authorityvirtue","authorityvice","sanctityvirtue","sanctityvice")
mfd_lackreg=list()
mfd_lack_noreg = list() # words (not stems) in mfd1 not in mfd2
for (i in 1:10){
  x = mfd_lack[[i]]
  z = c()
  z2 = c()
  for (j in 1:length(x)){
    m = grep("\\*", x[j])
    if (length(m)!=0){
      z = c(z, x[j])
      mfd_lackreg[[i]] = z
    } else {
      z2 = c(z2, x[j])
      mfd_lack_noreg[[i]] = z2
    }
  }
}
names(mfd_lackreg) = c("carevirtue","carevice","fairnessvirtue","fairnessvice","loyaltyvirtue","loyaltyvice","authorityvirtue","authorityvice","sanctityvirtue","sanctityvice")
names(mfd_lack_noreg) = c("carevirtue","carevice","fairnessvirtue","fairnessvice","loyaltyvirtue","loyaltyvice","authorityvirtue","authorityvice","sanctityvirtue","sanctityvice")

# work on the moralitygeneral category
z = c()
z2 = c()
x = unlist(mfd1_web[[11]])
for (j in 1:length(x)){
  m = grep("\\*", x[j])
  if (length(m)!=0){
    z = c(z, x[j])
    mfd_lackreg[[11]] = z
  } else {
    z2 = c(z2, x[j])
    mfd_lack_noreg[[11]] = z2
  }
}

# complete word stems
mfd_lackreg_complete = list()
for (i in 1:11){
  x = mfd_lackreg[[i]]
  if (length(x)!=0){
    m = c()
    for (j in 1:length(x)){
      url_keyword = x[j]
      url_head = "https://www.onelook.com/?w="
      url_tail = "&scwo=1&sswo=1&ssbp=1"
      url = paste0(url_head, url_keyword, url_tail)
      web = read_html(url) 
      words = web %>% html_nodes("br+ a") %>% html_text()
      m = c(m, words)
      Sys.sleep(5)
    }
    mfd_lackreg_complete[[i]] = m
  }
  print(length(mfd_lackreg_complete))
}

# reminder: mfd3 should be = mfd2 + mfd_noreg + mfd_reg
mfd3 = list()
for (i in 1:10){
  mfd3[[i]] = c(unlist(mfd2[[i]]),unlist(mfd_lack_noreg[[i]]), 
                unlist(mfd_lackreg_complete[[i]]))
}
mfd3[[11]] = c(unlist(mfd_lack_noreg[[11]]), 
               unlist(mfd_lackreg_complete[[11]]))

names(mfd3) = c("carevirtue","carevice","fairnessvirtue","fairnessvice","loyaltyvirtue","loyaltyvice","authorityvirtue","authorityvice","sanctityvirtue","sanctityvice","moralitygeneral")

#saveRDS(mfd3, "mfd3.rds") # mfd3 is the mfd list waiting to be translated

# N = 2,684 english words waiting to be translated
# transform the list to a dataframe
library(dplyr)
mfd3_df = data.frame()

for (i in 1:length(mfd3)){
  x = mfd3[[i]]
  df = data.frame(
    english = x,
    subgroup = names(mfd3[i])
  )
  mfd3_df = rbind(mfd3_df,df)
}

mfd3_df = mfd3_df %>% mutate(group = recode(subgroup,
                                            "authorityvice" = "authority",
                                            "authorityvirtue"= "authority",
                                            "carevice" = "care",
                                            "carevirtue" = "care",
                                            "fairnessvice" = "fairness",
                                            "fairnessvirtue" = "fairness",
                                            "loyaltyvice" = "loyalty",
                                            "loyaltyvirtue" = "loyalty",
                                            "sanctityvice" = "sanctity",
                                            "sanctityvirtue" = "sanctity",
                                            "moralitygeneral" = "general"))

```

### 1.2 MFD dictionary collection

To achieve the comprehensiveness of Chinese translations, we compared a listed of popular online [English-Chinese dictionaries](https://www.lexilogos.com/english/chinese_dictionary.htm). As a result, I decided to use [xiaoma English-Chinese online dictionary]( http://www.xiaoma.info/index.php?fdef=compensate). It is built based on [CC-CEDICT](https://cc-cedict.org/wiki/start) and [various other sources](http://www.xiaoma.info/help.php#sources). CC-CEDICT project is one of the biggest open, crowd-sourced online English-Chinese dictionary and it is a contiuation of CEDICT project which aims to construct Chinese-multilingual dictionaries across different languages. It provides a wide range of translations for a single Enligsh word. 

However, we should not overlook two limitations here. First, the Chinese translations might not be moral-relevant, for example "benefit" - "贾思勰".And it needs further human verifications. Second, some Chinese translations considered the Chinese context meaning. For example, ["benefit"](http://www.xiaoma.info/compound.php?def=benefit&fdef=benefit) would have a chinese translation "前事不忘，后事之师", which has little to do with the word "benefit" per se, but a translation based on the word usages/meanings in Chinese sentences. It does not say the translation is not accurate, instead, it indicates that we might need further contextual understanding of the translations.

Results were saved in `mfd5` and a sampled data structure is shown as below. We have 15,766 Chinese translations for 2,684 English moral words.

english|subgroup|group|chinese|
----|---|---|---|
benefit|care|virtute|利
obey|authorityvirtue|authority|尊从
arrest|authorityvirtue|authority|抓走
racism|fairnessvice|fairness|种族主义
abandon|carevice|care|捐
captain|authorityvirtue|authority|领队
comrades|loyaltyvirtue|loyalty|俦
denounce|authorityvice|authority|诟病
pain|carevice|care|痹证
admiral|authorityvirtue|authority|大将


```{r word translation}
library(writexl)
## translate English to Chinese
"http://www.xiaoma.info/compound.php?def=alleviate&fdef=alleviate"
url_head = "http://www.xiaoma.info/compound.php?def="
url_tail = "&fdef="
mfd3_trans = data.frame()
# write a function to catch error while scraping
get_webinfo <- function(x){
  out = tryCatch(
    expr = {
      web = read_html(x)
      Sys.sleep(sample(5:10,1))
      
      trans = web %>% html_nodes(".hanyu") %>% html_text()
      return(trans)
      message(paste0("no.", i, "; word:", mfd3_df$english[i], " good to go"))
    },
    error = function(e){
      message(paste0("no.", i, "; word:", mfd3_df$english[i]), ' is not a single word, so pass')
      trans = character(0)
      return(trans)
    }
  ) 
  return(out)
}

for(i in 588:length(mfd3_df$english)){
  url_keyword = mfd3_df$english[i]
  url = paste0(url_head, url_keyword, url_tail, url_keyword)
  
  trans = get_webinfo(url)
  # create a system sleep time, hope the website won't have strict anti-scraping problems
  
  if (length(trans)!=0){
    df = data.frame(
      english = mfd3_df$english[i],
      chinese = trans
    )
  } else {
    df = data.frame(
      english = mfd3_df$english[i],
      chinese = NA
    )
  }
  mfd3_trans = rbind(mfd3_trans,df)
  
  print(paste0("no.", i, "; word:", mfd3_df$english[i], "; numebr of translations:",length(trans)))
}
#saveRDS(mfd3_trans,"mfd3_trans.rds")

# pack document waited to be manually checked
mfd4 = left_join(mfd3_df, mfd3_trans, by = c("english"="english"))
# remove those withno Chinese translations (most of which are variants )
mfd5 = mfd4[!is.na(mfd4$chinese),]
mfd5 = mfd5[!duplicated(mfd5),] #remove duplicated rows

#saveRDS(mfd5,"mfd5.rds")

# write it out to excel
writexl:::write_xlsx(mfd5,"mfd5.xlsx")
```


